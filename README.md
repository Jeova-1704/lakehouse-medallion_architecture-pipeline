# ğŸ—ï¸ Arquitetura MedalhÃ£o (Bronze, Silver, Gold) e Data Lakehouse
Este projeto implementa um Data Lakehouse utilizando o Supabase como banco de dados para simular um ambiente de armazenamento e processamento de dados. O fluxo de dados segue a Arquitetura MedalhÃ£o (Bronze, Silver, Gold), garantindo qualidade, organizaÃ§Ã£o e eficiÃªncia no processamento dos dados.

## Arquitetrua/Fluxo de Dados atÃ© o momento 

![Arquitetura do projeto](images-readme/{AC48F041-C5B7-480D-BE44-3FFFCEAB4639}.png)

obs: Essa arquitetura Ã© uma representaÃ§Ã£o simplificada do fluxo de dados. A arquitetura final do projeto ainda estÃ¡ em desenvolvimento a medida que novas funcionalidades sÃ£o implementadas no projeto.

## Conceitos importantes

### ğŸ“Œ Data Lakehouse
Um Data Lakehouse Ã© uma arquitetura hÃ­brida que combina as melhores caracterÃ­sticas de Data Lakes e Data Warehouses. Ele permite armazenar grandes volumes de dados brutos (como um Data Lake) enquanto oferece governanÃ§a, qualidade e desempenho para consultas analÃ­ticas (como um Data Warehouse).
#### Principais CaracterÃ­sticas:
- Armazena dados estruturados e nÃ£o estruturados em um Ãºnico local.
- Suporta processamento de grandes volumes de dados com baixo custo.
- Permite consultas rÃ¡pidas e eficientes usando SQL e ferramentas analÃ­ticas.
- Possui governanÃ§a e controle de acesso, garantindo seguranÃ§a e qualidade dos dados.
- Facilita Machine Learning e AnÃ¡lises AvanÃ§adas, pois mantÃ©m dados histÃ³ricos em diferentes estÃ¡gios de processamento (Bronze, Silver, Gold na Arquitetura MedalhÃ£o).

### ğŸ“Œ Arquitetura MedalhÃ£o (Bronze, Silver, Gold)
A Arquitetura MedalhÃ£o Ã© um modelo de organizaÃ§Ã£o de dados dentro de um Data Lakehouse, estruturado em trÃªs camadas: Bronze, Silver e Gold. Cada camada representa um nÃ­vel de processamento e qualidade dos dados.

#### ğŸ“‚ Bronze
- Dados brutos extraÃ­dos de fontes externas.
- Sem limpeza ou transformaÃ§Ã£o.
- Armazenamento de dados em seu formato original.
- Ideal para armazenar dados histÃ³ricos e brutos para auditoria e rastreabilidade.

#### ğŸ“‚ Silver
- Dados limpos e transformados.
- Estruturados em tabelas relacionais
- Ideal para anÃ¡lises e consultas rÃ¡pidas.
- Armazenamento de dados prontos para anÃ¡lises e relatÃ³rios.

#### ğŸ“‚ Gold
- Dados agregados e prontos para anÃ¡lises avanÃ§adas.
- Estruturados em tabelas analÃ­ticas.
- Ideal para Machine Learning, Business Intelligence e AnÃ¡lises AvanÃ§adas.
- Armazenamento de dados prontos para insights e tomada de decisÃ£o.

### ğŸ“Œ Tecnologias e conceitos utilizados
- [Python](https://www.python.org/)
- [Pandas](https://pandas.pydata.org/)
- [Supabase](https://supabase.com/)
- [Arquitetura MedalhÃ£o (Bronze, Silver, Gold)](https://www.databricks.com/br/glossary/medallion-architecture)
- [Data-lakehouse](https://www.databricks.com/glossary/data-lakehouse)

### ğŸ“‚ Estrutura do Projeto
```bash
ğŸ“‚ pipeline-elt-lakehouse-medallion
â”œâ”€â”€ ğŸ“‚ images-readme/               â†’ Imagens utlizadas no readme
â”œâ”€â”€ ğŸ“‚ src/                         â†’ CÃ³digo-fonte do ETL
â”‚ â”œâ”€â”€ ğŸ“‚ elt/                       â†’ Pipelines de ETL
â”‚ â”‚ â”œâ”€â”€ ğŸ“‚ bronze/                  â†’ ExtraÃ§Ã£o dos dados brutos
â”‚ â”‚ â”‚ â”œâ”€â”€ main.py                   â†’ Script de extraÃ§Ã£o dos dados brutos e carregamento no schema bronze
â”‚ â”‚ â”œâ”€â”€ ğŸ“‚ silver/                  â†’ Limpeza e transformaÃ§Ã£o dos dados da camada bronze e upload na camada silver
â”‚ â”‚ â”‚ â”œâ”€â”€ clientes.py               â†’ Limpeza e transformaÃ§Ã£o dos dados dos clientes
â”‚ â”‚ â”‚ â”œâ”€â”€ LakehouseConnection.py    â†’ ConexÃ£o com o Supabase
â”‚ â”‚ â”‚ â”œâ”€â”€ main.py                   â†’ Script de limpeza e transformaÃ§Ã£o dos dados e carregamento no schema silver
â”‚ â”‚ â”‚ â”œâ”€â”€ pedidos.py                â†’ Limpeza e transformaÃ§Ã£o dos dados dos pedidos
â”‚ â”‚ â”‚ â”œâ”€â”€ produtos.py               â†’ Limpeza e transformaÃ§Ã£o dos dados dos produtos
â”‚ â”‚ â”œâ”€â”€ ğŸ“‚ gold                    â†’ AgregaÃ§Ã£o dos dados da camada silver e upload na camada gold
â”‚     â”œâ”€â”€LakehouseConnection.py     â†’ ConexÃ£o com o Supabase
â”‚     â”œâ”€â”€ main.py                   â†’ Script de agregaÃ§Ã£o dos dados e carregamento no schema gol
â”‚
â”œâ”€â”€ ğŸ“„ .env.example                 â†’ Exemplo de arquivo de variÃ¡veis de ambiente
â”œâ”€â”€ ğŸ“„ .gitignore                   â†’ Arquivo de configuraÃ§Ã£o do Git
â”œâ”€â”€ ğŸ“„ README.md                    â†’ DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ ğŸ“„ requirements.txt             â†’ DependÃªncias do projeto
```

## ğŸ“Œ 1ï¸âƒ£ Criando a Arquitetura MedalhÃ£o no Supabase
No Supabase, organizamos os dados em trÃªs esquemas:

ğŸ“‚ Bronze â†’ Dados brutos extraÃ­dos.
ğŸ“‚ Silver â†’ Dados limpos e transformados.
ğŸ“‚ Gold â†’ Dados agregados e prontos para anÃ¡lise.

### ğŸ”¹ Criando os Esquemas no Supabase
execute o cÃ³digo SQL no SQL Editor do Supabase para criar os esquemas:
```sql
-- Criar os esquemas para a arquitetura medalhÃ£o
CREATE SCHEMA bronze;
CREATE SCHEMA silver;
CREATE SCHEMA gold;
```

## ğŸ“Œ 2ï¸âƒ£ Criando a Camada Bronze

#### ğŸ“‚ Esquema bronze
```sql
CREATE SEQUENCE process_id_seq START 1;

CREATE TABLE bronze.clientes (
    id_cliente TEXT PRIMARY KEY,
    nome TEXT,
    email TEXT,
    telefone TEXT,
    cidade TEXT,
    idade TEXT,
    load_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP, 
    process_id TEXT DEFAULT 'abc' || nextval('process_id_seq')::TEXT
    row_version INT DEFAULT 1 
);

CREATE TABLE bronze.produtos (
    id_produto TEXT PRIMARY KEY,
    nome_produto TEXT,
    categoria TEXT,
    preco TEXT,
    estoque TEXT,
    load_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP, 
    process_id TEXT DEFAULT 'abc' || nextval('process_id_seq')::TEXT
    row_version INT DEFAULT 1 
);

CREATE TABLE bronze.pedidos (
    id_pedido TEXT PRIMARY KEY,
    id_cliente TEXT REFERENCES bronze.clientes(id_cliente),
    id_produto TEXT REFERENCES bronze.produtos(id_produto),
    quantidade TEXT,
    status TEXT,
    valor_total TEXT,
    data_pedido TEXT,
    load_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP, 
    process_id TEXT DEFAULT 'abc' || nextval('process_id_seq')::TEXT
    row_version INT DEFAULT 1 
);
```
Agora vamos dar as permissÃµes para o schema bronze:
```sql	
GRANT USAGE ON SCHEMA bronze TO anon;

GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE bronze.clientes TO anon;
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE bronze.produtos TO anon;
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE bronze.pedidos TO anon;
```

## ğŸ“Œ 3ï¸âƒ£ Criando a Camada Silver (TransformaÃ§Ã£o)
Agora aplicamos limpeza e transformaÃ§Ã£o nos dados.

```sql
CREATE TABLE silver.clientes (
    id_cliente TEXT PRIMARY KEY,
    nome TEXT,
    email TEXT,
    telefone TEXT,
    cidade TEXT,
    idade INT,
    data_ingestao TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE silver.produtos (
    id_produto TEXT PRIMARY KEY,
    nome_produto TEXT,
    categoria TEXT,
    preco NUMERIC,
    estoque INT,
    data_ingestao TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE silver.pedidos (
    id_pedido TEXT PRIMARY KEY,
    id_cliente TEXT REFERENCES silver.clientes(id_cliente),
    id_produto TEXT REFERENCES silver.produtos(id_produto),
    quantidade INT,
    status TEXT,
    valor_total NUMERIC,
    data_pedido DATE,
    data_ingestao TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```
Agora vamos dar as permissÃµes para o schema silver:
```sql
GRANT USAGE ON SCHEMA silver TO anon;

GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE silver.clientes TO anon;
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE silver.produtos TO anon;
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE silver.pedidos TO anon;
```

## ğŸ“Œ 4ï¸âƒ£ Criando a Camada Gold (AnÃ¡lises)
Agora agregamos os dados para anÃ¡lises.
```sql
CREATE TABLE gold.analise_clientes_pedidos (
    id_cliente TEXT PRIMARY KEY,
    nome TEXT,
    cidade TEXT,
    idade INT,
    total_pedidos INT,
    total_gasto NUMERIC,
    data_primeiro_pedido DATE,
    data_ultimo_pedido DATE,
    categorias_compradas TEXT, -- Lista de categorias
    produtos_comprados TEXT -- Lista de produtos
);
CREATE TABLE gold.analise_produtos (
    id_produto TEXT PRIMARY KEY,
    nome_produto TEXT,
    categoria TEXT,
    total_vendido INT,
    total_receita NUMERIC,
    estoque_atual INT
);
```
##### Explicando as colunas das tabelas gold:
###### gold.analise_clientes_pedidos
- total_gasto â†’ Soma do valor total do pedido (igual ao pedido, pois cada cliente tem um Ãºnico pedido).
- status_pedido â†’ Status do pedido (Pago, Cancelado, etc.).
- data_pedido â†’ Data da compra.
- categoria_produto â†’ Categoria do produto comprado.
- nome_produto â†’ Nome do produto comprado.
###### gold.analise_produtos
- total_vendido â†’ Soma das quantidades vendidas de cada produto.
- total_receita â†’ Soma do valor total gerado por esse produto.
- estoque_atual â†’ Estoque restante do produto.


Agora vamos dar as permissÃµes para o schema gold:
```sql
GRANT USAGE ON SCHEMA gold TO anon;

GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE gold.analise_clientes_pedidos TO anon;
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE gold.analise_produtos TO anon;
```

#### ğŸ“Œ 5ï¸âƒ£ Configurando a exposiÃ§Ã£o dos schemas no lakehouse
Para permitir interaÃ§Ã£o externa e acesso via API aos schemas, Ã© necessÃ¡rio configurar corretamente as permissÃµes no Supabase.

1ï¸âƒ£ Acesse o painel do Supabase e vÃ¡ atÃ© as configuraÃ§Ãµes de polÃ­tica de acesso.
2ï¸âƒ£ Habilite o acesso Ã s tabelas dos schemas Bronze, silver e gold para usuÃ¡rios anÃ´nimos e autenticados.
3ï¸âƒ£ Garanta que as permissÃµes de leitura e escrita estejam corretas.

#### ğŸ“Œ Exemplo de configuraÃ§Ã£o no Supabase:
Antes de iniciar a extraÃ§Ã£o e carga dos dados, Ã© essencial verificar as limitaÃ§Ãµes de requisiÃ§Ã£o do Supabase para garantir que o processamento seja eficiente.

#### ğŸ“Œ Limites definidos para requisiÃ§Ãµes:
- ExtraÃ§Ã£o de dados: Limitada a 100.000 registros por requisiÃ§Ã£o.
- InserÃ§Ã£o de dados: Limitada a 10.000 registros por requisiÃ§Ã£o.
ğŸ”¹ ImplementaÃ§Ã£o do Batch Processing
Para garantir que todos os dados sejam inseridos corretamente no schema Bronze, silver e gold, utilizamos um sistema de processamento em lote (batch processing). Esse sistema divide os dados em pequenos blocos de 10.000 registros por requisiÃ§Ã£o, otimizando a performance e evitando erros de timeout.
![alt text](images-readme/{170A5D3A-B50F-49F7-BC09-D43B159DBB83}.png)


#### ğŸ“Œ 6ï¸âƒ£ Executando o projeto
1ï¸âƒ£ Clone o repositÃ³rio:
```bash
git clone [link do repositÃ³rio]
```
2ï¸âƒ£ Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```
3ï¸âƒ£ Renomeie o arquivo .env.example para .env e preencha as variÃ¡veis de ambiente:
```bash
# Databse destination
LAKEHOUSE_URL="adicione a url do supabase aqui"
LAKEHOUSE_KEY="adicione a chave do supabase aqui"

# Database origin
SUPABASE_URL="adicione a url do supabase de onde os dados serÃ£o extraÃ­dos"
SUPABASE_KEY="adicione a chave do supabase de onde os dados serÃ£o extraÃ­dos"
```
4ï¸âƒ£ Execute o projeto da da pipeline elt completa (bronze, silver, gold):
```bash
python src/app.py
```

#### ğŸ“Œ 7ï¸âƒ£ ConclusÃ£o
Este projeto implementa um Lakehouse gratuito usando Supabase e Arquitetura MedalhÃ£o para organizar os dados de uma loja fictÃ­cia.

âœ… Criamos as Camadas Bronze, Silver e Gold.
âœ… Transformamos e estruturamos os dados.
âœ… Agora os dados estÃ£o prontos para anÃ¡lise! ğŸš€ğŸ”¥


#### ğŸ“Œ 8ï¸âƒ£ PrÃ³ximos Passos
âœ… Finalizamos a Arquitetura MedalhÃ£o com sucesso! ğŸ‰
ğŸš€ Agora podemos avanÃ§ar para novos desafios:

1ï¸âƒ£ Criar um Pipeline de Dados.
2ï¸âƒ£ Criar um Dashboard para anÃ¡lise dos dados.
3ï¸âƒ£ Criar uma API para disponibilizar os dados.
